# 科大讯飞用户新增预测挑战赛

## 数据探索与处理笔记

> 对应的文件是[code\xunfei-eda.ipynb]，这部分代码是在 Kaggle 跑的，因为当时还没遇到必须降级 Python 的问题

🌟 **数据加载与初探**

首先，我们从`/kaggle/input/Xunfei-dataset/train.csv`路径加载了比赛的训练数据。这是一个规模庞大的数据集，包含了高达 620,356 条记录！🔍

下面是数据的前几行概览：

```
   uuid  eid                           udmap      common_ts  x1  x2  x3   x4   x5  x6  x7  x8  target
0     0   26  {"key3":"67804","key2":"650"}  1689673468244   4   0  41  107  206   1   0   1       0
1     1   26  {"key3":"67804","key2":"484"}  1689082941469   4   0  41   24  283   4   8   1       0
2     2    8                        unknown  1689407393040   4   0  41   71  288   4   7   1       0
```

📌 **关键观察**：数据集包括以下列：'uuid', 'eid', 'udmap', 'common_ts', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 和 'target'。

🌟 **数据预处理**

1. **缺失值处理**

   我们对`udmap`列进行了一次深入探索，特别是对"unknown"这个值。为了确定是否需要丢弃这一列，我们计算了"unknown"值的比例。

2. **特征选择**

   基于上述的缺失值分析及其他原因，我们决定从数据集中删除`uuid`和`udmap`两列，以简化后续的数据处理和模型训练。

删除后的数据如下：

```
   eid      common_ts  x1  x2  x3   x4   x5  x6  x7  x8  target
0   26  1689673468244   4   0  41  107  206   1   0   1       0
1   26  1689082941469   4   0  41   24  283   4   8   1       0
2    8  1689407393040   4   0  41   71  288   4   7   1       0
```

🎉 **小结**

至此，我们已完成了数据的初步加载和预处理。接下来，我们可以进一步进行数据可视化、特征工程或直接进入模型训练阶段！💡

🌟 **进一步数据探索**

1. **时间转换**

   - 从`common_ts`列中，我们提取了毫秒时间戳，并将其转换为日期格式。示例时间戳转换为了`2023-07-18`。

2. **时间特征工程**

   - 对`common_ts`列进行了一次转换，计算了相对于 2023 年的进度百分比。

3. **特定列探索** - `x3`
   - 查看了`x3`列中 41 这个值的比例。结果显示大约 14%的数据有这个值。
   - 了解了`x3`的可能取值，并发现它与`target`列的某些值存在强相关。

### 时间特性的魔力 ✨

- 我们发现数据集中的时间戳是毫秒级别的。一个例子是，我们取出了一个时间戳并将其转换为了日期`2023-07-18`。这给我们提供了有关数据时段的宝贵信息。

- 为了更好地利用这个时间戳，我们对`common_ts`列进行了特征工程，计算了相对于 2023 年的进度百分比。

### 深入探索`x3`列 🕵️

- 为了深入了解`x3`列，我们首先查看了值为 41 的频率，大约 14%的数据有这个值。

- 我们还探讨了`x3`列的不同取值，发现某些值与`target`列的值存在明显的相关性。这为后续的特征选择或特征工程提供了有力的线索。

继续深入您的笔记本，我们发现了对其他特征列的探索：

继续深入您的笔记本，我们发现了对其他特征列的探索：

🌟 **特定列探索** - `x8` 和 `x1`

6. **探索 `x8` 列**

   - 查看了`x8`列中值为 1 的频率，大约 85.5%的数据有这个值。
   - 了解了`x8`的所有可能取值，只有[0, 1]。
   - 探索了`x8`的取值与`target`列的关系，发现：

     ```
     x8=0 and target=0: 10.86%
     x8=0 and target=1: 3.59%
     x8=1 and target=0: 75.08%
     x8=1 and target=1: 10.46%
     ```

7. **探索 `x1` 列**

   - 了解了`x1`的所有可能取值，有[0, 1, 2, 3, 4]。
   - 探索了`x1`的取值与`target`列的关系，发现例如：

     ```
     x1=0 and target=0: 17.26%
     x1=1 and target=0: 13.41%
     ...
     x1=0 and target=1: 2.73%
     x1=1 and target=1: 2.01%
     ...
     ```

### 对 `x8` 和 `x1` 列的探索 🔍

- **`x8` 列探索**：

  - 我们观察到 `x8` 列中有 85.5%的数据的值为 1。
  - 进一步探索发现，`x8` 列只有两个可能的值：0 和 1。
  - 最有趣的是，我们发现 `x8` 的值与 `target` 列有明显的关系。例如，当 `x8=0` 时，大约 10.86%的数据`target=0`，而 3.59%的数据`target=1`。

- **`x1` 列探索**：

  - `x1` 列有 5 个可能的取值：[0, 1, 2, 3, 4]。
  - 这一列的值与 `target` 列也有明显的关系。例如，当 `x1=0` 时，大约 17.26%的数据`target=0`，而 2.73%的数据`target=1`。

---

这两列的探索为我们提供了关于数据的有价值的见解，也可能为特征工程和模型训练提供指导。

🌟 **特定列探索** - `eid`

1. **探索 `eid` 列**

   - `eid`列包含 43 个不同的值，范围从 0 到 42。
   - 对于每一个`eid`的值，我们都探索了其与`target`列的关系。例如：

     ```
     eid=0 and target=0: 0.80%
     eid=0 and target=1: 0.06%
     eid=1 and target=0: 0.06%
     eid=1 and target=1: 0.06%
     ...
     ```

### 对 `eid` 列的深入探索 🔎

- **`eid` 列探索**：

  - `eid`列真的很有趣！我们发现了它包含 43 个不同的值，从 0 到 42。
  - 当我们深入探索`eid`列的每一个值与`target`列的关系时，我们得到了许多有价值的见解。例如，对于`eid=0`，大约 0.80%的数据有`target=0`的值，而 0.06%的数据有`target=1`的值。类似地，对于`eid=1`，约 0.06%的数据`target=0`，约 0.06%的数据`target=1`。

---

这个`eid`列的探索提供了关于数据的又一层有价值的见解，也可能为特征工程和模型训练提供指导。

## 运用机器学习模型笔记

> 这部分代码是在百度飞桨 AI Studio 跑的，没整明白 Kaggle 平台 Python 降级的方法，而飞桨有 Python 3.7 和 V100 的环境

拼接`test.csv`和`train.csv`，按照数据探索处理部分的操作对数据进行处理。

### 调用 AutoML

如果数据科学是一种现代魔法，那么自动机器学习（AutoML）就是一种强大的咒语。只需几行代码，它就能自动选择最佳的模型和参数。

```python
from flaml import AutoML
automl = AutoML()
automl.fit(train_X, train_y, task="classification")
```

这就像是用魔法书中的一个咒语解决了一个复杂的问题。

从它的输出日志中，我们可以获得以下关键信息：

### 模型选择与迭代

1. **任务类型**: 分类 (`task = classification`)
2. **评估方法**: 持有验证 (`Evaluation method: holdout`)
3. **误差度量**: \(1-\text{准确度}\) (`Minimizing error metric: 1-accuracy`)
4. **参与的模型**: 包括`lgbm`, `rf`, `xgboost`, `extra_tree`, `xgb_limitdepth`, `lrl1`等多个模型。

### 模型性能

- **最佳模型**: `lgbm`（LightGBM）
- **最佳错误率**: \(0.0472\)，也就是准确率约为 \(0.9528\) 或 \(95.28%\)

### 时间与迭代

- **总迭代次数**: 95 次（或更多，因为日志可能被截断）
- **寻找最佳模型所需时间**: 约 1172 秒（约 20 分钟）

### 警告与注意事项

- 存在`ConvergenceWarning`，意味着一些模型（如`lrl1`）在给定的迭代次数内没有完全收敛。

## 故事化解释 🎭

想象一下，你是一位寻宝猎人，正在一个神秘的岛上寻找传说中的“最准确的预测模型”。你有多种工具（模型）可供选择：神奇的“lgbm”指南针、坚固的“rf”石锤、闪亮的“xgboost”宝剑等。

在这次的寻宝之旅中，你并不孤单，因为有一个名叫“AutoML”的智能助手陪伴你。每一次尝试都像是挖掘一个可能藏有宝藏的地点。

经过不懈的努力和几次险象环生的冒险后（警告和未收敛的模型），你终于找到了那个传说中最准确的“lgbm”指南针，它的准确度高达 95.28%！

现在，你拥有了一把能指引你走向正确路径的神奇指南针，而这一切只花了你 20 分钟的时间。

🌟 是不是感觉整个过程就像一场充满刺激和惊喜的寻宝冒险呢？ 🌟

这些结果告诉我们以下几点：

### 训练集表现：

- **准确度（Accuracy）**: \(0.9953\) 或 \(99.53%\)
- **F1 分数**: \(0.9869\)

这说明模型在训练集上表现极其出色，几乎能完美地分类样本。

### 验证集表现：

- **准确度（Accuracy）**: \(0.9547\) 或 \(95.47%\)
- **F1 分数**: \(0.8586\)

这表明模型在未见过的数据上也有相当好的表现，虽然与训练集相比有所下降。

### 综合解读：

1. **过拟合**: 虽然训练集的表现非常好，但与验证集相比，性能有所下降。这可能是过拟合的迹象，但幅度不大。
2. **模型可靠性**: 验证集的准确度和 F1 分数仍然很高，说明模型具有很好的泛化能力。
3. **类别不平衡**: F1 分数通常用于衡量在类别不平衡情况下的模型性能。验证集上的 F1 分数较低可能意味着模型对于少数类的识别能力有待提高。

### 最终分数

\(0.82752\)
